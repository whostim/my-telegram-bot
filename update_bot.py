import re
import os

def update_bot_file():
    # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª
    with open('universal_search_bot.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # 1. –û–±–Ω–æ–≤–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é format_date
    new_format_date = '''def format_date(date_str):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç –¥–¥.–º–º.–≥–≥–≥–≥, —É–±–∏—Ä–∞–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""
    if not date_str:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–∏
    relative_patterns = [
        r'\\d+\\s*(–º–µ—Å|–º–µ—Å—è—Ü|–º–µ—Å—è—Ü–µ–≤|–º–µ—Å—è—Ü–∞)',
        r'\\d+\\s*(–≥–æ–¥|–≥–æ–¥–∞|–ª–µ—Ç)',
        r'\\d+\\s*(–¥–µ–Ω—å|–¥–Ω—è|–¥–Ω–µ–π)',
        r'\\d+\\s*(–Ω–µ–¥–µ–ª|–Ω–µ–¥–µ–ª–∏|–Ω–µ–¥–µ–ª—å)',
        r'\\d+\\s*(—á–∞—Å|—á–∞—Å–∞|—á–∞—Å–æ–≤)',
        r'\\d+\\s*(–º–∏–Ω—É—Ç|–º–∏–Ω—É—Ç—ã)',
        r'—Ç–æ–ª—å–∫–æ —á—Ç–æ',
        r'–≤—á–µ—Ä–∞',
        r'—Å–µ–≥–æ–¥–Ω—è',
        r'\\d+[–¥–≥–º—á–Ω]',  # –°–æ–∫—Ä–∞—â–µ–Ω–∏—è: 10–¥, 5–≥, 2–º –∏ —Ç.–¥.
        r'\\d+\\s*—á\\.?\\s*–Ω–∞–∑–∞–¥',
        r'\\d+\\s*–¥\\.?\\s*–Ω–∞–∑–∞–¥',
        r'\\d+\\s*–Ω–µ–¥\\.?\\s*–Ω–∞–∑–∞–¥',
        r'\\d+\\s*–º–µ—Å\\.?\\s*–Ω–∞–∑–∞–¥',
        r'\\d+\\s*–≥\\.?\\s*–Ω–∞–∑–∞–¥'
    ]
    
    for pattern in relative_patterns:
        if re.search(pattern, date_str.lower()):
            return ""
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –¥–∞—Ç—ã
    try:
        from datetime import datetime
        formats_to_try = [
            '%Y-%m-%d',
            '%d.%m.%Y',
            '%d/%m/%Y',
            '%m/%d/%Y',
            '%B %d, %Y',
            '%b %d, %Y',
            '%d %B %Y',
            '%d %b %Y',
            '%Y-%m-%dT%H:%M:%S',
            '%Y-%m-%d %H:%M:%S',
            '%d.%m.%Y %H:%M',
            '%Y-%m-%dT%H:%M:%S.%fZ',
            '%Y-%m-%dT%H:%M:%S%z'
        ]
        
        for fmt in formats_to_try:
            try:
                dt = datetime.strptime(date_str.strip(), fmt)
                return dt.strftime('%d.%m.%Y')
            except ValueError:
                continue
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.debug(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç—ã '{date_str}': {e}")
    
    return "'''
    
    # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é format_date
    content = re.sub(
        r'def format_date\(date_str\):.*?return date_str',
        new_format_date,
        content,
        flags=re.DOTALL
    )
    
    # 2. –û–±–Ω–æ–≤–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é handle_text
    new_handle_text = '''@dp.message()
async def handle_text(message: types.Message):
    user_text = message.text.strip()

    buttons = [
        "üîç –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π",
        "üåç –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏",
        "‚ö° –°–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏",
        "üìä –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫"]
    if user_text.startswith('/') or user_text in buttons:
        return

    await message.answer(f"üîç –ò—â—É –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{user_text}'...")

    try:
        if any(word in user_text.lower()
           for word in ['russia', 'russian', 'international']):
            search_type = "international"
        else:
            search_type = "all"

        articles = await news_searcher.universal_search(user_text, search_type)

        if articles:
            russian_articles = [a for a in articles if a.get('language') == 'ru']
            english_articles = [a for a in articles if a.get('language') == 'en']

            response = f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ '{user_text}':\\n\\n"

            if russian_articles and search_type != "international":
                response += "üá∑üá∫ –†–æ—Å—Å–∏–π—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:\\n\\n"
                for i, article in enumerate(russian_articles[:4], 1):
                    response += f"{i}. {article['title']}\\n"
                    
                    # –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                    source = article.get('source', '').strip()
                    if not source:
                        source = "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω"
                    response += f"   üì∞ {source}\\n"
                    
                    # –£–±–∏—Ä–∞–µ–º –¥–∞—Ç—É –ø–æ–ª–Ω–æ—Å—Ç—å—é - –Ω–µ –≤—ã–≤–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É —Å –¥–∞—Ç–æ–π
                    response += f"   üîó {article['url']}\\n\\n"

            if english_articles and search_type == "international":
                response += "üåç –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:\\n\\n"
                for i, article in enumerate(english_articles[:4], 1):
                    response += f"{i}. {article['title']}\\n"
                    
                    # –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                    source = article.get('source', '').strip()
                    if not source:
                        source = "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω"
                    response += f"   üì∞ {source}\\n"
                    
                    # –£–±–∏—Ä–∞–µ–º –¥–∞—Ç—É –ø–æ–ª–Ω–æ—Å—Ç—å—é - –Ω–µ –≤—ã–≤–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É —Å –¥–∞—Ç–æ–π
                    response += f"   üîó {article['url']}\\n\\n"

            response += f"üìä –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(articles)}"

        else:
            response = f"üòî –ü–æ –∑–∞–ø—Ä–æ—Å—É '{user_text}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π.\\n\\n"
            response += "üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –∑–∞–ø—Ä–æ—Å–∞."

        await message.answer(response)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")'''
    
    # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é handle_text
    content = re.sub(
        r'@dp.message\(\)\\s*async def handle_text\(message: types.Message\):.*?await message\.answer\(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ\. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å\."\)',
        new_handle_text,
        content,
        flags=re.DOTALL
    )
    
    # 3. –û–±–Ω–æ–≤–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é fresh_news
    new_fresh_news = '''@dp.message(lambda message: message.text == "‚ö° –°–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏")
async def fresh_news(message: types.Message):
    await message.answer("‚ö° –ò—â—É —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏")

    try:
        articles = await news_searcher.get_fresh_news_today()

        if articles:
            response = "‚ö° –°–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏:\\n\\n"

            for i, article in enumerate(articles, 1):
                response += f"{i}. {article['title']}\\n"
                
                # –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                source = article.get('source', '').strip()
                if not source:
                    source = "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω"
                response += f"   üì∞ {source}\\n"
                
                # –£–±–∏—Ä–∞–µ–º –¥–∞—Ç—É –ø–æ–ª–Ω–æ—Å—Ç—å—é - –Ω–µ –≤—ã–≤–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É —Å –¥–∞—Ç–æ–π
                response += f"   üîó {article['url']}\\n\\n"

                if len(response) > 3500:
                    response += "... (–ø–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ —Å—Ç–∞—Ç—å–∏)"
                    break

        else:
            response = "üòî –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è.\\n\\n"
            response += "üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É."

        await message.answer(response)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")'''
    
    # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é fresh_news
    content = re.sub(
        r'@dp.message\(lambda message: message\.text == "‚ö° –°–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏"\)\\s*async def fresh_news\(message: types\.Message\):.*?await message\.answer\("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π\. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ\."\)',
        new_fresh_news,
        content,
        flags=re.DOTALL
    )
    
    # 4. –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä—Å–µ—Ä –Ø–Ω–¥–µ–∫—Å.–ù–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    new_yandex_parser = '''    async def search_yandex_news_direct(self, query):
        try:
            session = await self.get_session()
            encoded_query = urllib.parse.quote(query)
            url = f"https://yandex.ru/news/search?text={encoded_query}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
            }

            async with session.get(url, headers=headers) as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')

                    articles = []

                    news_cards = soup.find_all('article', class_='mg-card')[:10]

                    for card in news_cards:
                        try:
                            title_elem = card.find('h2', class_='mg-card__title') or card.find('a', class_='mg-card__link')
                            if not title_elem:
                                continue

                            title = title_elem.get_text().strip()
                            link = title_elem.get('href', '')

                            if link.startswith('https://news.yandex.ru/yandsearch?'):
                                match = re.search(r'cl4url=([^&]+)', link)
                                if match:
                                    link = urllib.parse.unquote(match.group(1))
                            elif link.startswith('/'):
                                link = f"https://yandex.ru{link}"

                            source_elem = card.find('span', class_='mg-card-source__source')
                            time_elem = card.find('span', class_='mg-card-source__time')
                            desc_elem = card.find('div', class_='mg-card__annotation')

                            # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                            source_text = ""
                            if source_elem:
                                source_text = source_elem.get_text().strip()
                                # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                                source_text = re.sub(r'\\s+', ' ', source_text)
                            
                            # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ URL
                            if not source_text and link:
                                try:
                                    domain = urllib.parse.urlparse(link).netloc
                                    source_text = domain.replace('www.', '').split('.')[0]
                                    source_text = source_text.capitalize()
                                except:
                                    pass
                            
                            # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                            if not source_text:
                                source_text = "–Ø–Ω–¥–µ–∫—Å.–ù–æ–≤–æ—Å—Ç–∏"

                            if link and not any(
                                domain in link for domain in [
                                    'google.com/search',
                                    'yandex.ru/search']):
                                articles.append({
                                    'title': title,
                                    'url': link,
                                    'source': source_text,
                                    'date': time_elem.get_text().strip() if time_elem else '',
                                    'description': desc_elem.get_text().strip() if desc_elem else '',
                                    'language': 'ru'
                                })
                        except Exception as e:
                            logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏ –Ø–Ω–¥–µ–∫—Å: {e}")
                            continue

                    return articles
            return []
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –Ø–Ω–¥–µ–∫—Å.–ù–æ–≤–æ—Å—Ç–µ–π: {e}")
            return []'''
    
    # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π –ø–∞—Ä—Å–µ—Ä –Ø–Ω–¥–µ–∫—Å.–ù–æ–≤–æ—Å—Ç–µ–π
    content = re.sub(
        r'async def search_yandex_news_direct\(self, query\):.*?return \[\]',
        new_yandex_parser,
        content,
        flags=re.DOTALL
    )
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    with open('universal_search_bot.py', 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω!")
    print("üìù –ò–∑–º–µ–Ω–µ–Ω–∏—è:")
    print("   - –£–±—Ä–∞–Ω—ã –≤—Å–µ –¥–∞—Ç—ã –∏–∑ –≤—ã–≤–æ–¥–∞")
    print("   - –£–ª—É—á—à–µ–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
    print("   - –î–æ–±–∞–≤–ª–µ–Ω–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–¥–ø–∏—Å—å –∏—Å—Ç–æ—á–Ω–∏–∫–∞")
    print("   - –£–ª—É—á—à–µ–Ω –ø–∞—Ä—Å–µ—Ä –Ø–Ω–¥–µ–∫—Å.–ù–æ–≤–æ—Å—Ç–µ–π")

if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
    import shutil
    shutil.copy2('universal_search_bot.py', 'universal_search_bot_backup.py')
    print("üì¶ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: universal_search_bot_backup.py")
    
    update_bot_file()
